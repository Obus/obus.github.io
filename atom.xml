<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[DataDeep]]></title>
  <link href="http://datadeep.ru/atom.xml" rel="self"/>
  <link href="http://datadeep.ru/"/>
  <updated>2014-11-20T02:34:58+04:00</updated>
  <id>http://datadeep.ru/</id>
  <author>
    <name><![CDATA[Команда datadeep.ru]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Оптимизация в машинном обучении]]></title>
    <link href="http://datadeep.ru/blog/2014/11/14/optimizatsiia-v-mashinnom-obuchienii/"/>
    <updated>2014-11-14T12:07:51+04:00</updated>
    <id>http://datadeep.ru/blog/2014/11/14/optimizatsiia-v-mashinnom-obuchienii</id>
    <content type="html"><![CDATA[<p><img src="http://datadeep.ru/images/optim_surface.png" width="768" height="576" title="Surface" />
<script type="math/tex">
\newcommand{loss}{\ell}
\newcommand{risk}{F}
\newcommand{hyp}{h}
\newcommand{eps}{\varepsilon}
</script></p>

<p>Привет, читатель! Обсуждая науку о данных, нельзя не упомянуть машинное обучение, а говоря о машинном обучении, никак невозможно пройти мимо такой темы как <em>оптимизация</em>. Что же такое оптимизация и какая она бывает? Как оптимизация связана с машинным обучением? Как быть быстрее, оптимальнее, точнее? </p>

<p>Если эти вопросы вызывают интерес — заходите.</p>

<!-- more -->

<h2 id="section">Связь оптимизации и машинного обученния</h2>

<p>Что такое оптимизация? В двух словах, оптимизация (как область знаний) изучает как <em>что-то</em> сделать <em>лучше</em>. Вернее, как <em>что-то</em> сделать <em>наилучшим образом</em>, то есть — <em>оптимально</em>. Оптимальность, обычно, понимается в смысле максимизации или минимизации определенного значения. Например, мы можем искать наиболее выгодную стратегию игры на бирже, максимизируя ожидаемую прибыль, или аэродинамически наиболее эффективную форму кузова автомобиля, минимизируя сопротивление воздуха. Конечно же, этими примерами оптимизация не ограничивается, встречаясь повсеместно. Можно даже придти к выводу, что практически любой процесс — оптимизационный с той или иной точки зрения, но это, скорее, вопрос философский.</p>

<p>Разобравшись с оптимизацией “на пальцах”, определим ее формально, а формально задача математической оптимизации записывается следующим образом:</p>

<script type="math/tex; mode=display">
\risk(\theta) \longrightarrow \min\limits_{\theta\in\mathcal{X}}.
</script>

<p>Так вот, просто и незатейливо. Но постойте, кто эти <script type="math/tex">\risk</script>, <script type="math/tex">\theta</script>, <script type="math/tex">\mathcal{X}</script> и какое отношение они имеют к машинному обучению?</p>

<p>Оказывается, большинство задач машинного обучения формулируются именно таким образом: в виде минимизации некоего функционала <script type="math/tex">\risk</script> по некоторому параметру <script type="math/tex">\theta</script>. Например, в случае задачи классификации или регрессии мы стараемся предсказывать одну переменную (<script type="math/tex">y</script>) на основе другой (<script type="math/tex">x</script>) с помощью набора функций–“оракулов” <script type="math/tex">\{\hyp_\theta\}_{\theta\in\mathcal{X}}</script>, выбирая наилучшую из них на основе <em>обучающей выборки</em> <script type="math/tex">\{x_i, y_i\}_{i=1}^N</script> — в таком случае мы хотим минимизировать ошибку предсказания на имеющейся выборке. Ошибку предсказания чаще всего записывают как</p>

<script type="math/tex; mode=display"> \risk(\theta) = \sum_{i=1}^n \loss(\hyp_{\theta}(x_i), y_i),</script>

<p>где <script type="math/tex">\loss(\hyp_{\theta}(x_i), y_i)</script> — мера отличия предсказания <script type="math/tex">\hyp_{\theta}(x_i)</script> от истинного значения <script type="math/tex">y_i</script>. Чтобы не витать в облаках, рассмотрим конкретный вид <script type="math/tex">\risk(\theta)</script> для двух распространенных методов машинного обучения: метода <script type="math/tex">K</script>-средних и линейной регрессии с квадратичной функцией потерь.</p>

<h4 id="k-">Метод <script type="math/tex">K</script>-средних</h4>

<p>Этот метод решает задачу кластеризации — разбиения множества точек <script type="math/tex">\{x_i\}_1^N</script> на <script type="math/tex">K</script> (<script type="math/tex">\leq N</script>) непересекающихся множеств-кластеров.  Результат кластеризации методом $K$-средних — это, во-первых, разбиение множества ${1,\ldots,N}$ на <script type="math/tex">K</script> кластеров: <script type="math/tex">\{\mathcal{C}_k\}_1^K</script> и, во-вторых, центр каждого из этих кластеров: <script type="math/tex">\{\mu_k\}_1^K</script>. Функция <script type="math/tex">\risk(\theta)</script> для метода $K$-средних записывается следующим образом</p>

<script type="math/tex; mode=display">
\risk\left(\theta = (K, \{\mathcal{C}_k\}_1^K, \{\mu_j\}_1^K)\right) = \sum_{K=1}^K \sum_{i\in \mathcal{C}_k} (x_i - \mu_k)^2 \to \min\limits_{\theta},
</script>

<p>— то есть метод <script type="math/tex">K</script>-средних ищет такое разбиение множества <script type="math/tex">\{x_i\}_1^N</script> на кластеры, чтобы сумма расстояний от каждой точки до центра кластера, которому она принадлежит, была минимальна.</p>

<h4 id="section-1">Линейная регрессия с квадратичной функцией потерь</h4>

<p>Этот метод решает задачу регрессии — предсказания выходов <script type="math/tex">y_i\in\mathbb{R}</script> по входам <script type="math/tex">x_i=(x_i^{(1)},\ldots,x_i^{(p)})^T\in\mathbb{R}^p</script> на основе обучающей выборки <script type="math/tex">\{ x_i, y_i \}_1^N</script>. Метод линейной регрессии “предполагает”, что выход <script type="math/tex">y</script> может быть представлен в виде линейной функции от входов <script type="math/tex">x_i^{(1)},\ldots,x_i^{(p)}</script> и от параметров <script type="math/tex">\theta^{(1)},\ldots,\theta^{(p)}</script>: <script type="math/tex">y = \sum_{j=1}^p \theta^{(j)} x^{(j)}</script>. <script type="math/tex">\risk(\theta)</script> записывается следующим образом:</p>

<script type="math/tex; mode=display">
\risk(\theta) = \sum_{i=1}^N (x_i^T\theta - y_i)^2 \to \min\limits_{\theta},
</script>

<p>— здесь минимизируется среднеквадратичное отклонение “предсказаний” <script type="math/tex">x_i^T\theta</script> от истинных значений <script type="math/tex">y_i</script>.</p>

<p>Таким образом, и метод <script type="math/tex">K</script>-средних и линейная регрессия минимизируют конкретные функции <script type="math/tex">F(\theta)</script> (вся хитрость методов, в том <strong>как</strong> они это делают), решая частные задачи оптимизации. Приложив определенные усилия, функция <script type="math/tex">\risk(\theta)</script> может быть выписана для сколь угодно сложной модели, например, для сверточной нейронной сети. Но мы этого делать не будем: и так хорошо понятно, что в машинном обучении оптимизация играет очень важную роль. </p>

<h2 id="section-2">Математическая оптимизация</h2>

<p>Решив, что оптимизация в машинном обучении, а значит и в нашем арсенале — must have, обсудим ее по-подробнее.</p>

<p>Математическая оптимизация зародилась в XVIII–XIX века и окончательно оформилась в XX веке. За этот срок у нее появилось множество видов, подвидов, методов и приложений. Как мы и упомянали выше, общая задача оптимизации ставится следующим образом</p>

<script type="math/tex; mode=display">
\risk(\theta) \longrightarrow \min\limits_{\theta\in\mathcal{X}},
</script>

<p>но от настолько общей постановки мало толку — совершенно непонятно как ее решать: не имея информации о природе <script type="math/tex">\risk</script> и <script type="math/tex">\mathcal{X}</script>, мы безоружны, можем только вслепую тыкать “пальцем в небо” (вернее, в <script type="math/tex">\mathcal{X}</script>) в надежде попасть в точку минимума.
Собственно, чем не вариант, есть даже схожий по идее метод с вполне себе научным названием: метод <em>равномерного поиска</em> (aka перебора). Суть его, как вы уже догадались, состоит в том, чтобы наложить <script type="math/tex">\varepsilon</script>-сетку на множество <script type="math/tex">\mathcal{X}</script> и измерить функцию <script type="math/tex">\risk</script> в каждом узле сетки. Так найдется узел <script type="math/tex">\hat\theta</script> с наименьшим значением <script type="math/tex">\risk</script>, и … пользы от этого знания будет чуть больше чем никакой.
Без дополнительных ограничений на <script type="math/tex">\risk</script> и/или <script type="math/tex">\mathcal{X}</script> наш <script type="math/tex">\hat\theta</script> ничего не говорит ни о наимаеньшем значении <script type="math/tex">\risk^* = \min\limits_{\theta\in\mathcal{X}} \risk(\theta)</script> не о соответствующем аргументе <script type="math/tex">\theta^* = \arg\min\limits_{\theta\in\mathcal{X}} \risk(\theta)</script>. Действительно, <script type="math/tex">\risk</script> может меняться сколь угодно быстро, принимая между узлами сетки какие угодно значения, а то и вовсе быть разрывной. То есть знания о функции в узлах не говорит ничего о ней вне этих узлов. Так вот, старались-старались, считали функцию в каждом узле, а сидим теперь у разбитого корыта.</p>

<p>Но унывать всякий может, а надо это дело исправить. В чем наша проблема?
Проблема наша в излишнней свободе функции $\risk$, точнее в неограниченной скорости ее изменения. </p>

<p>Так давайте ее ограничим! Например, вот так:</p>

<script type="math/tex; mode=display">
|\risk(\theta_1) - \risk(\theta_2)| \leq L |\theta_1 - \theta_2|
</script>

<p>т.е. мы запретили <script type="math/tex">\risk</script> менятся как угодно быстро, ограничив ее изменение линейно изменением ее аргумента (это условие на <script type="math/tex">\risk</script>, называется <em>условием Липшица</em>, очень, кстати, полезное и распространенное свойство в оптимизации). Теперь наша оценка <script type="math/tex">\hat\theta</script> кое-чего стоит:</p>

<script type="math/tex; mode=display">|\risk(\hat\theta) - \risk^*| \leq \varepsilon L \sqrt{p}, </script>

<p>где <script type="math/tex">p</script> — размерность <script type="math/tex">\mathcal{X}</script>. Местоположении <script type="math/tex">\theta^*</script>, однако, до сих пор остается загадкой.</p>

<p>Можно продолжить модифицировать метод перебора, добиваясь лучших гарантий точности (как по параметру, так и по значению функции), и увеличивая вычислительную эффективность (мы вычислили <script type="math/tex">\risk</script> порядка <script type="math/tex">O\left(\frac{V(\mathcal{X})}{\varepsilon^p}\right)</script> раз, где <script type="math/tex">V(\mathcal{X})</script> — объем <script type="math/tex">\mathcal{X}</script>, что даже в невинном единичном кубе при <script type="math/tex">\varepsilon = 0.01</script> даст миллион). Но это займет немало времени, а метод перебора интересен нам сейчас с той только точки зрения, что демонстрирует две важные идеи:</p>

<ol>
  <li><a href="http://www.no-free-lunch.org/">There is no free lucnh</a>. Чтобы эффективно решить задачу оптимизации, нам нужно ее ограничить — сузить круг поисков. Тем быстрее и точнее мы хотим ее решить, тем более жесткие ограничения нам придется накладывать;</li>
  <li>Лучшее — враг хорошего. Иногда достаточно найти приближенное к оптимальному решение, сэкономив при этом на ресурсах.</li>
</ol>

<p>Как было сказано, оптимизация как наука обширна и изучает множество различных задач и методов. Все, однако, нам рассматривать не нужно: в машинном обучении актуальны только некоторые из них, в частности очень распространены так называемые <em>градиентные методы</em>. Нам градиентные методы интересны как с точки зрения того, что развивают две усвоенные ранее идеи, так и из тех соображений, что они являются основой для многих других методов оптимизации. Именно о градиентных методах и пойдет речь далее.</p>

<h2 id="section-3">Градиентные методы</h2>

<p>Идея градиентных методов в том, что в каждой точке <script type="math/tex">\theta_0</script> мы можем измерить градиент функции <script type="math/tex">\nabla \risk(\theta_0)</script>, который подскажет нам, как изменяется функция в окрестности <script type="math/tex">\theta</script>. Попробуем объяснить, откуда растут ноги у этой идеи: зафиксируем <script type="math/tex">\theta_0</script>, <script type="math/tex">\delta</script> и расмотрим разложение функции <script type="math/tex">\risk</script> в ряд Тейлора в точке <script type="math/tex">\theta_0 + \delta</script>:</p>

<script type="math/tex; mode=display">
\risk(\theta_0 + \delta) = \risk(\theta_0) +
\nabla \risk(\theta)\delta +
\nabla^2 \risk(\theta_0) \frac{\delta^2}{2} +
\ldots +
\nabla^n \risk(\theta_0) \frac{\delta^n}{n!} +
\ldots
</script>

<p><script type="math/tex">\delta</script> предполагается достаточно малым, поэтому <script type="math/tex">\delta^n</script> убывает очень быстро и обычно рассматривают только первую компоненту:</p>

<script type="math/tex; mode=display">
\risk(\theta_0 + \delta) \simeq \risk(\theta_0) +
\nabla \risk(\theta)\delta.
</script>

<p>Таким образом, в окрестности точки <script type="math/tex">\theta_0</script> мы приблизили <script type="math/tex">\risk</script> линейной функцией. Градиентные методы эксплуатируют это приближение, полагаясь на то, что минимизация <script type="math/tex">\risk</script> эквивалентна минимизации ее линейного приближения в небольшой окрестности точки <script type="math/tex">\theta_0</script>. А что такое “небольшая окрестность”? Ограничим ее шаром с радиусом <script type="math/tex">\alpha</script> <script type="math/tex">(\mid\delta\mid \leq \alpha)</script>, тогда на этой окрестности минимум будет достигаться при</p>

<script type="math/tex; mode=display">
\delta^* = \arg\min\limits_{|\delta|\leq \alpha} \risk(\theta_0) + \nabla \risk(\theta)\delta = - \alpha\frac{\nabla \risk(\theta)}{|\nabla \risk(\theta)|}.
</script>

<p>Фактически, мы сделали шажок длиной <script type="math/tex">\alpha</script> в направлении <em>противоположном</em> направлению градиента <script type="math/tex">\nabla \risk(\theta)</script>. Это вполне логично, ведь направление градиента — это направление наибольшего роста функции, а противоположное ему — направление наискорейшего ее уменьшения. В этом и заключается основная идея градиентных методов: шаг за шагом, спускаться против направления градиента к минимуму. С этими знаниями можем уже сформулировать простенький алгоритм оптимизации</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{eqnarray*}
&\textbf{def}& \; \text{simple_gradient_descent}(\risk, \, \theta_0, \, \alpha):
\\
& \quad & k \leftarrow 0
\\
& \quad & \textbf{while} \; not \; converged \; :
\\
& \quad & \qquad k \leftarrow k + 1
\\
& \quad & \qquad \theta_k \leftarrow \theta_{k-1} - \alpha\frac{\nabla \risk(\theta_{k-1})}{|\nabla \risk(\theta_{k-1})|}
\\
& \quad & \text{return}\; \theta_k
\end{eqnarray*}
 %]]&gt;</script>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{eqnarray*}
&\textbf{Algorithm}& \; \text{SimpleGradientDescent}
\\
& \;\;\text{Input:} \; \theta_0, & \risk, \, \alpha
\\
& \;\;\text{Output:}\; \hat{\theta} &
\\
& \quad & k \leftarrow 0
\\
& \quad & \textbf{while} \; not \; converged \; \textbf{do}:
\\
& \quad & \qquad k \leftarrow k + 1
\\
& \quad & \qquad \theta_k \leftarrow \theta_{k-1} - \alpha\frac{\nabla \risk(\theta_{k-1})}{|\nabla \risk(\theta_{k-1})|}
\\
& \quad & \textbf{done}
\\
& \quad & \textbf{return}\; \theta_k
\end{eqnarray*}
 %]]&gt;</script>

<p>Действительно, ничего сложного: один за другим делаем шажочки длиной <script type="math/tex">\alpha</script> против направления градиента. Условие остановки <script type="math/tex">not\;converged</script> мы пока конкретизировать не будем, это может быть условие на максимальное количество итераций (<script type="math/tex">% &lt;![CDATA[
k < k_{max} %]]&gt;</script>), изменение значения функции <script type="math/tex">% &lt;![CDATA[
f(\theta_{k-1}) - f(\theta_{k}) < \eps %]]&gt;</script>, параметра <script type="math/tex">% &lt;![CDATA[
||\theta_{k-1} - \theta_{k}||_2 < \eps %]]&gt;</script>, нам сейчас это не важно (справедливости ради, на практике зачастую оказывается одним из важнейших вопросов).
Алгоритм выглядит разумно, но у него есть серьезный недостаток: он учитывает только направление, но не длину градиента. Так мы можем сделать слишком маленький шаг там, где градиент велик, тем самым увеличив количество итерации, либо слишком большой шаг там, где градиент мал, пройдя мимо точки оптимума.</p>

<p>К счастью, мы можем избавится от этих недостатков, немного изменив наш алгоритм</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{eqnarray*}
&\textbf{def}& \; \text{gradient_descent}(\risk, \, \theta_0, \, \alpha):
\\
& \quad & k \leftarrow 0
\\
& \quad & \textbf{while} \; not \; converged \;:
\\
& \quad & \qquad k \leftarrow k + 1
\\
& \quad & \qquad \theta_k \leftarrow \theta_{k-1} - \alpha_k\nabla \risk(\theta_{k-1})
\\
& \quad & \text{return}\; \theta_k
\end{eqnarray*}
 %]]&gt;</script>

<p>Этот “алгоритм” есть ни что иное, как метод <em>градиентного спуска</em> (<em>gradient descent</em>). Известно, что при некоторых условиях на <script type="math/tex">\risk</script> и <script type="math/tex">\alpha_k</script> (например, <script type="math/tex">\risk</script> выпукла, <script type="math/tex">\nabla \risk</script> удовлетворяет условию Липшица, а <script type="math/tex">\alpha_k = \alpha</script> ), значение <script type="math/tex">\risk</script> в оценках метода градиентного спуска <script type="math/tex">\theta_k</script> стремится к оптимальному</p>

<script type="math/tex; mode=display">
|\risk(\theta_k) - \risk^*| \xrightarrow{k\to\infty} 0
</script>

<p>— это не может не радовать.</p>

<p>Теперь у нас есть теоретически обоснованный алгоритм оптимизации, пора применить его в боевых условиях.</p>

<h2 id="section-4">Пример. Линейная регрессия с использованием метода градиентного спуска</h2>

<p>Выше мы уже упомянали задачу линейной регрессии (с квадратичной функцией ошибки). Напомним ее целевую функцию <script type="math/tex">\risk</script>:</p>

<script type="math/tex; mode=display">
\risk(\theta) = \sum_{i=1}^N (x_i^T\theta - y_i)^2 \to \min\limits_{\theta},
</script>

<p>В матричном виде она записывается как</p>

<script type="math/tex; mode=display">
\risk(\theta) = ||X\theta - y||_2^2 = (X\theta - y)^T (X\theta - y) \to \min\limits_{\theta},
</script>

<p>где <script type="math/tex">X\in\mathbb{R}^{N\times p}</script> — матрица, чьи строки — <script type="math/tex">x_i</script>, а <script type="math/tex">y = (y_1,\ldots,y_N)</script>.
Существует аналитическое решение этой задачи: <script type="math/tex">\hat\theta = (X^T X)^{-1} X^T y</script> (оценка <a href="http://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BD%D0%B0%D0%B8%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B8%D1%85_%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82%D0%BE%D0%B2">методом наименьших квадратов</a>). Но, операция обращения матрицы довольно <a href="http://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations#Matrix_algebra">дорогая</a>, в особенности в задачах, где размерность <script type="math/tex">x</script> огромна и матричные операции просто не могут быть выполнены в памяти.
К счастью, наша функция <script type="math/tex">\risk</script> удовлетворяет всем необходимым условиям и для нее выполняется соотношение <script type="math/tex">|\risk(\theta_k) - \risk^*| \xrightarrow{k\to\infty} 0</script>. Поэтому, мы имеем полное право воспользоваться методом градиентного спуска.</p>

<p>В первую очередь нам нужны данные: <script type="math/tex">\{x_i, y_i\}_1^N</script>, для простоты возьмем модельные (<script type="math/tex">N=1000</script>):</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{eqnarray*}
&x^{(1)}_i & \sim \mathcal{N}(0, 1), \quad &i=1,\ldots, 1000
\\
&y_i &= 2 x^{(1)}_i - 0.5 + \varepsilon_i, \qquad &\varepsilon_i \sim \mathcal{N}(0, 1).
\end{eqnarray*}
 %]]&gt;</script>

<p>То есть все <script type="math/tex">x_i^{(1)}</script> распределены по стандартному нормальному закону, а <script type="math/tex">y_i</script> — линейная функция от <script type="math/tex">x_i^{(1)}</script> с аддитивной помехой (так же имеющей стандртное нормальное распределение). Ниже изображены эти данные в плоскости <script type="math/tex">(x^{(1)}, y)</script>.
<img src="http://datadeep.ru/images/data.png" width="768" height="576" title="Data" /></p>

<p>“Лишний” индекс <script type="math/tex">^{(1)}</script> к <script type="math/tex">x^{(1)}</script> мы добавили неспроста: если обозначить <script type="math/tex">x_i^{(2)}=1</script> для всех <script type="math/tex">i</script>, то можно переписать <script type="math/tex">y_i = 2 x_i^{(1)} - \frac{1}{2}x_i^{(2)} + \varepsilon_i</script> и более того, в матричной форме</p>

<script type="math/tex; mode=display">y = X\theta^* + \varepsilon.</script>

<p>где </p>

<script type="math/tex; mode=display">% &lt;![CDATA[

	y = (y_1,\ldots,y_n)^T,
\\
	X = \begin{pmatrix}
		x_1^{(1)} & x_1^{(2)} \\ 
		x_2^{(1)} & x_2^{(2)} \\ 
		\vdots & \vdots \\
		x_n^{(1)} & x_n^{(2)}
	\end{pmatrix},
\\
	\varepsilon =(\varepsilon_1,\ldots,\varepsilon_n)^T,
\\
 	\text{a }\, \theta^*=(2, -\frac{1}{2}).
 %]]&gt;</script>

<p>Итак, мы определили <script type="math/tex">X</script> и <script type="math/tex">y</script> (и неизвестный нам по легенде <script type="math/tex">\theta^*</script>). Для того, чтобы воспользоваться методом градиентного спуска остается найти производную <script type="math/tex">\nabla \risk</script>, что довольно просто:</p>

<script type="math/tex; mode=display">
\nabla \risk(\theta) =\nabla_\theta \left[ (X\theta - y)^T (X\theta - y)\right] = X^T (X\theta - y) .
</script>

<p>Теперь все готово. Остается применить метод градиентного спуска к задаче линейной регрессии со сгенерированными нами данными.
Зададим <script type="math/tex">\alpha=0.0001</script>. Ниже иллюстрируется работа нашего алгоритма: как изменялась линия регрессии, построенная по оценкам <script type="math/tex">(\theta_k^{(1)},\theta_k^{(2)})</script>, на каждой итерации.</p>

<p><img src="http://datadeep.ru/images/LinearRegression_GradientDescent_50iter.gif" width="768" height="576" title="Gradient Descent iterations" /></p>

<p>Успех: за 56 итераций мы получили приближение c точностью до второго знака после запятой как по параметру <script type="math/tex">(\mid\mid\theta^* - \theta_{56}\mid\mid \sim 0.02)</script>, так и по значению функции $($F(\theta_{56}) - F(\theta^*) \sim 0.07)$</p>

<h2 id="section-5">Заключение</h2>
<p>Надеюсь, мне удалось ответить на вопросы, заданные в самом начале статьи. Мы поставили общую задачу оптимизации, на паре примеров узнали как она связана с задачей машинного обучения, и логично пришли к методу градиентного спуска, даже применив его на практике. Вполне неплохо, в последующих статьях я постараюсь лучше раскрыть тему применения алгоритмов оптимизации в машинном обучении и прояснить некоторые интересные детали.</p>

<p>Напоследок, порекомендую пару интересных материалов по теме:</p>

<ul>
  <li><a href="http://www.mdk-arbat.ru/bookcard?book_id=3326320">Введение в оптимизацию. Поляк Б.Т.</a> — книга от ученого с мировым именем, не только формальным, но и доступным языком рассказывает об основнах оптимизации, помогая уяснить в первую очередь не конкретные задачи и метода, а идеи, стоящие за ними;</li>
  <li><a href="http://web.stanford.edu/class/ee364a/">EE364a: Convex Optimization. Бойд С.</a> — записанные курсы Стэндфордского университета по выпуклой оптимизации (мы этого еще не знаем, но методы выпуклой оптимизации — если не самые важные, то абсолютно незаменимые в машинном обучении);</li>
  <li><a href="http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4%D1%8B_%D0%BE%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8_%D0%B2_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%BC_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B8_%28%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9%29">Методы оптимизации в машинном обучении. Кропотов Д.А.</a> — развернутое содержание курса лекций факультета вычислительной математики и кибернетики МГУ. Без конспектов, к сожалению но с отличной подборкой литературы;</li>
  <li><a href="https://www.coursera.org/course/ml">Machine learning</a> — курс посвященный машинному обучению от известного ученого и сооснователя сервиса онлайн-обучения <a href="https://www.coursera.org">Coursera.org</a> Andrew Ng, который помимо объяснения самих алгоритмов большое внимание уделяет вопросу оптимизации. Между прочим, картинка для привлечения внимания взята из слайдов одной и лекций этого курса (лекции второй недели, посвященные простейшей линейной регрессии).</li>
</ul>

<p>До встречи!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Что такое Data Science?]]></title>
    <link href="http://datadeep.ru/blog/2014/11/07/chto-takoie-data-science/"/>
    <updated>2014-11-07T15:08:41+04:00</updated>
    <id>http://datadeep.ru/blog/2014/11/07/chto-takoie-data-science</id>
    <content type="html"><![CDATA[<p>Блог datadeep.ru будет посвящён <em>Data Science</em> (<em>Науке о данных</em>, по-русски её также иногда называют <em>Даталогия</em>). Поэтому первый пост в блоге мне представляется логичным посвятить описанию науки о данных в представлении авторов блога, чтобы читатель мог составить для себя мнение о том, что его ждёт в дальнейшем.</p>

<p><img src="http://datadeep.ru/images/data_science.jpg" width="768" height="576" title="Data Science" /></p>

<!-- more -->

<p><a href="http://blog.andreamostosi.name/2014/09/how-to-stay-updated-about-data-science-and-big-data/">Первоисточник картинки.</a></p>

<p>В последние несколько лет в науке и промышленности можно наблюдать повышенный интерес к новой области знания, называемой Data Science или Наука о данных. Компания McKinsey оценивает нехватку специалистов к 2018 году в 140 000 - 190 000 человек. Журнал Harvard Business Review назвал науку о данных одной из самых перспективных профессий (the sexiest job) XXI века. Резко возрос спрос на таких специалистов.</p>

<p><img src="http://datadeep.ru/images/Data_Scientist_Job_Trend.png" title="Job Trends" /></p>

<p>Такие компании, как Google, Facebook, Microsoft, Apple, Linkedin, Baidu активно нанимают к себе профессионалов в области науки о данных. В Интернете появилось большое количество ресурсов, посвящённых Data Science, например, различные MOOC (online-курсы по Machine Learning и Data Mining на образовательных сайтах), специализированные блоги. В прессе появляется всё больше сообщений об успехах в области науки о данных. Университеты предлагают студентам программы обучения по Data Science (например, Имперский колледж Лондона, Вашингтонский университет, Нью-Йоркский университет и т.д.). Что же такое — наука о данных? </p>

<p>Потребность в анализе данных, нахождении в них закономерностей во многом обусловлена феноменом Big Data, т.е. необходимостью в манипулировании и обработке данных огромных объёмов, различной природы, часто плохо структурированных. Это стало возможно благодаря развитию Интернета и технологий хранения и передачи информации. У компаний накопилось очень много различных данных, и закономерно появилась задача извлечения из них полезной информации, которая может помочь в принятии решений. Традиционным подходом к проблемам такого вида была статистика, получившая большое развитие в XX веке. Однако, одних возможностей, которые предоставляет статистический аппарат, мало для всестороннего анализа больших неструктурированных данных. Стало понятно, что специалисту по анализу данных необходим сплав знаний из различных областей математики, статистики, информатики и предметной области знаний. Кроме того, стоит выделить в отдельную категорию задачи, связанные с искусственным интеллектом, такие как компьютерное зрение, обработка естественного языка, речи. Таким образом, Data Science является весьма эклектичной дисциплиной, это хорошо показано на диаграмме (ставшей обязательной для статей о Data Science, <a href="http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram">первоисточник</a>):</p>

<p><img src="http://datadeep.ru/images/venn_diag.png" title="Venn Diagram" /></p>

<p>На мой взгляд, основные области, в которых требуются знания человеку, занимающемуся наукой о данных (его называют <em>data scientist</em> или иногда <em>датологом</em>) являются статистика и математика, машинное обучение, информатика (Computer Science), различные прикладные области. Сделаем их краткий обзор. Однако, перед этим давайте разберёмся с самим термином “наука о данных”.</p>

<p>Сейчас можно найти огромное количество различной информации на этот счёт: от Википедии до блогов. Во всех этих источниках нет чёткого и однозначного определения Data Science, что не удивительно, потому что наука о данных — ещё очень молодая и активно развивающаяся область знания, она не успела как следует оформиться ни в академических кругах, ни в обществе. </p>

<p>Существует несколько более-менее устоявшихся в научной литературе и публицистике терминов, связанных с наукой о данных: Data Science, Data Mining (интеллектуальный анализ данных), Machine Learning (машинное обучение). Значения и взаимосвязь этих терминов в разных источниках могут трактоваться по-разному, я рассматриваю Machine Learning как часть Data Mining, которая в свою очередь входит в понятие Data Science. В этой статье я постараюсь рассказать, чем является наука о данных на мой взгляд. </p>

<h2 id="section">Статистика и математика</h2>

<p>Для успешного применения алгоритмов анализа данных, для того, чтобы иметь возможность их исследовать и модернизировать под нужды конкретной задачи, важна базовая математическая подготовка на уровне университетских курсов. Нужны знания в линейной алгебре, математическом анализе, функциональном анализе, теории графов. Конечно, вполне возможно просто применять готовые решения к данным (например, библиотеки Apache Mahout для Java, scikit-learn для Python, множество пакетов для языка R и т.д.), однако для получения наилучшего результата анализа данных часто бывает необходима настройка алгоритмов для решения поставленной задачи, и человек, обладающий соответствующей математической подготовкой, имеет большую свободу в этом вопросе. И я не говорю про научное исследование методов анализа данных, в этом случае ясно, что без знания математических основ не обойтись. Отмечу, что на мой взгляд для успешной практики в Data Science не требуются глубокие знание в описанных выше областях, но вполне могут возникнуть задачи, для решения которых потребуется увеличить познания в какой-то из этих тем, например, для решения задачи кластеризации на графах явно не будет лишним повысить осведомлённость в теории графов.</p>

<p>Особняком стоит теория вероятностей. Она является базой для математической статистики и машинного обучения. Почти все методы анализа данных основаны на ней. Кроме того, существует перспективный класс методов стохастической оптимизации, который использует аппарат теории вероятностей, а оптимизация является составной частью машинного обучения. Про машинное обучение и оптимизацию будет рассказано дальше. Исходя из всего этого, достаточно глубокие знания в теории вероятностей очень важны для успешного анализа данных.</p>

<p>Одним из краеугольных камней Data Science является математическая статистика. Это наука, которая на основе ограниченной выборки позволяет сделать выводы о структуре данных, используя для оценки точности этих выводов теорию вероятностей. Статистический аппарат представляет собой совокупность различных методов построения вероятностных моделей для описания природы случайных событий. Долгое время анализ данных и статистика были практически синонимами. Можно выделить несколько разделов статистики. Такие методы, как построение таблиц, графиков данных, выделение различных количественных показателей из данных (среднее значение, стандартное отклонение, эксцесс, квантиль, математическое ожидание, дисперсия и т.д.) являются элементами описательной статистики. Она часто применяется при первичной обработке данных для того, чтобы составить некоторое первоначальное представление о них. С этой процедурой связаны методы очистки данных, т.е. удаления инородных, ненужных элементов, которые могут отрицательно сказаться на результатах анализа. Кроме того, стоит упомянуть связанные с предыдущими процедуры Data Munging или Data Wrangling, которые используют визуализацию, статистические модели, методы описательной статистики и другие подходы для преобразования данных в некоторый более удобный для дальнейшей работы вид.</p>

<p>Следующим разделом статистики являются методы оценивания. Они позволяют по выборке данных построить оценки различных параметров (в предположении, что данные описываются некоторыми вероятностными распределениями): математического ожидания, стандартного отклонения, квантилей, плотности и функции распределений. Также существуют методы, которые строят так называемые доверительные интервалы для искомых параметров. Другой важной областью является проверка статистических гипотез, задача которой состоит в проверке утверждений о распределении случайной величины по выборке из данных. Для этого строятся доверительная, критическая области, статистика критерия (с помощью выборки) и проверяется её попадание в одну из этих областей, на основании чего делаются некоторые вероятностные выводы о том, отвергается ли утверждение. Сюда относятся такие понятия, как ошибки первого и второго рода, мощность критерия, уровень значимости.</p>

<h2 id="section-1">Машинное обучение</h2>

<p>Следующей частью, входящей в состав науки о данных, является <em>Машинное обучение</em> (<em>Machine Learning</em>). Существует большое количество вариантов определения этого понятия. В книге Тома Митчелла (Tom Mitchell) “Machine Learning” приводится следующее объяснение (довольно часто цитируемое):</p>

<blockquote>
  <p>Будем говорить, что компьютерная программа обучается из опыта E относительно некоторого класса задач T и меры качества P, если качество её работы на задачах из T, измеренное с помощью P, возрастает с опытом E.</p>
</blockquote>

<p>Машинное обучение применяется в тех случаях, когда существует некоторая закономерность, структура в данных, которую необходимо извлечь, но это нельзя сделать обычным математическим путём, и для достижения поставленной цели используются данные. Таким образом, можно сказать, что машинное обучение занимается обучением модели из доступных данных так, чтобы она наилучшим образом обобщалась на неизвестные данные относительно некоторой меры качества.</p>

<p>Существует несколько близких к понятию Machine Learning, а, зачастую, и обозначающих его в книгах и статьях, терминов: <em>Statistical Learning</em> и <em>Pattern Recognition</em>. Statistical learning (статистическое обучение) встречается в работах, связанных с теорией Вапника-Червоненкиса, машиной опорных векторов (SVM), обобщающей способностью алгоритмов. Pattern recognition (распознавание образов) часто упоминается в статьях и книгах по кибернетике и математической оптимизации.</p>

<p>Рассмотрим основные классы методов машинного обучения. Пусть входные данные состоят из объектов, имеющих как наблюдаемые свойства, так и ненаблюдаемые, но известные. Алгоритмы, которые вычисляют эти ненаблюдаемые свойства по наблюдаемым, причём не только для входных данных, но и для любых других, называются алгоритмами <em>обучения с учителем</em> (<em>supervised learning</em>). Т.е. тренировочная выборка данных состоит из пар $(x_k, y_k)$, где $x_k$ — объект данных, а $y_k$ — некоторое числовое значение. На практике обычно строят хотя бы алгоритм, который ошибается не очень часто и не очень сильно. После обучения получается модель $h_{\theta}(x)$, зависящая от параметров $\theta$, и принимающая на вход новые объекты, для которых предсказывает соответствующее числовое значение. Задачи обучения с учителем различают в зависимости от природы $y_k$: если $y_k$ означает принадлежность к какому-то классу (метка класса), т.е. принимает значения на ограниченном множестве целых чисел, то задача называется задачей <em>классификации</em> (или <em>распознавания</em>), в противном случае, когда $y_k$ может быть любым вещественным числом, задача называется <em>задачей регрессии</em>. Примеры методов этого класса: метод $k$ ближайших соседей, логистическая регрессия, нейронные сети, машина опорных векторов, наивный байесовский классификатор.</p>

<p>Приведу пример работы алгоритма обучения с учителем. На картинке ниже изображены данные: ярким цветом — тренировочные, более блёклым — тестовые.</p>

<p><img src="http://datadeep.ru/images/supervised_learning_data.png" title="Supervised Learning Data" /></p>

<p>На следующей картинке изображён результат работы метода $k$ ближайших соседей на этих данных, ошибка классификации: $0.9$.</p>

<p><img src="http://datadeep.ru/images/supervised_learning_res.png" title="Supervised Learning Result" /></p>

<p>Существует и класс алгоритмов <em>обучения без учителя</em> (<em>unsupervised learning</em>). В этом случае входные данные состоят только из объектов $x_k$. Обучение без учителя является очень важным разделом машинного обучения, т.к. данных, не имеющих меток (например, картинок, для которых не указано, что на них изображено), в огромное количество раз больше, чем размеченных данных, потому что метки классов чаще всего расставляются вручную. К этому классу алгоритмов можно отнести методы понижения размерности данных, <em>обучения признаков</em> (<em>feature learning</em>), но одними из самых используемых являются методы <em>кластерного анализа</em> (<em>cluster analysis</em>). Пусть входные данные состоят из объектов с некоторыми наблюдаемыми свойствами. Алгоритм, который разбивает данные на группы (кластеры) и определяет, какому кластеру принадлежит объект, называется алгоритмом <em>кластеризации</em>. Данные разбиты на группы так, что внутри каждого кластера объекты похожи, а объекты из разных кластеров — непохожи. При этом такое разбиение статистически верно не только для входных данных, но и для новых, неизвестных ранее объектов. Примеры: метод $k$-средних, спектральная кластеризация, анализ главных компонент (PCA).</p>

<p>Проиллюстрирую работу алгоритма обучения без учителя. На картинке ниже изображены входные не размеченные данные.</p>

<p><img src="http://datadeep.ru/images/unsupervised_learning_data.png" title="Unsupervised Learning Data" /></p>

<p>На следующей картинке изображён результат работы метода $k$-средних для $k=3$.</p>

<p><img src="http://datadeep.ru/images/unsupervised_learning_res.png" title="Unsupervised Learning Result" /></p>

<p>В отдельный класс выделяют алгоритмы <em>обучения с подкреплением</em> (<em>reinforcement learning</em>). Это особый вид машинного обучения, при котором обучение происходит путём взаимодействия с внешней средой. На вход такому алгоритму подаются данные, состоящие из $(x_k, y_k)$, где $y_k$ — некая реакция среды. Обучение с подкреплением является очень интересной областью для исследований, которая активно используется в кибернетике и робототехнике. Хорошими примерам задач для методов этого класса являются игры. Например, существуют реализации алгоритмов обучения с подкреплением для игры в шахматы или в “Space Invaders” (компания <a href="http://deepmind.com/">DeepMind</a>). Примером таких методов может служить Q-обучение. </p>

<p>Двумя основными дисциплинами, на пересечении которых находится машинное обучение, являются статистика и математическая оптимизация. О статистики мы уже говорили в предыдущем разделе. Алгоритмы машинного обучения строят вероятностные модели, используя аппарат теории вероятностей и математической статистики, например, широко применяются такие инструменты, как байсовская статистика, анализ главных компонент, факторый анализ, анализ временных рядов, метод максимума правдоподобия, корреляционный анализ и т.д.</p>

<p>Оптимизация — это класс задач нахождения некоторых наилучших, оптимальных значений для достижения поставленной цели. Говоря более формально, задача оптимизации заключается в нахождении максимума или минимума (экстремума) целевой функции при выполнении некоторых линейных или нелинейных ограничений. Методами решения таких задач занимается математическое программирование. Оптимизация исключительно важна для машинного обучения, потому что после выбора модели необходимо найти её оптимальные параметры. Эта процедура сводится к минимизации некоторого функционала среднего риска</p>

<script type="math/tex; mode=display">
F(\theta) \to \min_{\theta},
</script>

<p>задаваемого с помощью меры ошибки. Например, достаточно распространённой является квадратичная мера ошибки, тогда </p>

<script type="math/tex; mode=display">
F(\theta) = \frac{1}{N} \sum_{k=1}^N (y_k - h_{\theta}(x_k))^2.
</script>

<p>Этот процесс и называется обучением. В машинном обучении широко применяются такие алгоритмы оптимизации, как градиентный спуск,  квазиньютоновский метод, метод множителей Лагранжа, стохастическая оптимизация и другие.</p>

<p>Методы оптимизации — это сердце каждого алгоритма машинного обучения, т.к. именно с помощью них происходит непосредственно обучение. От них во многом зависит скорость работы и количество используемых ресурсов. Развитие машинного обучения напрямую связано с развитием техник оптимизации. К примеру, открытие и развитие метода обратного распространения ошибки оказало большое влияние на возобновление интереса учёных и практиков к нейронным сетям. Многие открытые проблемы алгоритмов машинного обучения связаны с задачами оптимизации. <em>Вычислительная теория обучения</em> (<em>Computational Learning Theory</em>) занимается вопросами, во многом относящимися к оптимизации в машинном обучении. Существуют конференции, посвящённые проблемам оптимизации в машинном обучении, например крупная конференция <a href="http://orfe.princeton.edu/conferences/colt2015/the-conference/announcements/announcement-2014-10-04-134500">Conference on Learning Theory</a>. В последнее время в связи с развитием концепции Big Data становится актуальной задача распределённых вычислений и оптимизации в машинном обучении.</p>

<p>Кроме того, хочется отметить значимую роль машинного обучения в кибернетике и исследованиях, связанных с искусcтвенным интеллектом. Оно является важной частью ИИ, и развитие в этой области во многом сопряжено с прогрессом в машинном обучении. Алгоритмы машинного обучения позволяют компьютеру самостоятельно извлекать информацию из данных в процессе работы и помогают ему принимать решения. При использовании этих методов исследователи добиваются значительного прогресса в таких областях искусственного интеллекта, как понимание машиной текстов, человеческой речи, компьютерное зрение, синтез речи. Кроме того, с помощью алгоритмов машинного обучения создаются интеллектуальные сервисы, такие как переводчики с одного языка на другой, системы, рекомендующие контент на соответствующих сайтах и т.д. Учёные в области искусственного интеллекта активно занимаются исследованиями в машинном обучении, например, известный футуролог Рэймонд Курцвейл работает в должности технического директора в области машинного обучения и обработки естественного языка в компании Google.</p>

<h2 id="computer-science--">Computer Science и программирование</h2>

<p>Навыки в области Computer Science (информационных технологий) очень важны для того, кто занимается Data Science. В одной из <a href="http://www.quora.com/What-is-the-difference-between-a-data-scientist-and-a-statistician">дискуссий на Quora</a> я встретил такое определение: </p>

<blockquote>
  <p>Человек, занимающийся наукой о данных — это тот, кто лучше разбирается в статистике, чем любой программист, и лучше разбирается в программировании, чем любой статистик.</p>
</blockquote>

<p>Data scientist является практиком, а не теоретиком. Он постоянно работает с данными и исследует работу алгоритмов машинного обучения на практике. Для этого он использует различные технологии, языки программирования и библиотеки.</p>

<p>Для разработки прикладных программ тому, кто занимается наукой о данных, нужно знать некоторые теоретические вещи из Computer Science: классические алгоритмы и структуры данных, умение оценивать вычислительную сложность алгоритмов, знание принципов объектно ориентированного программирования и шаблонов проектирования. </p>

<p>Из языков программирования наиболее распространёнными и востребованными в области анализа данных являются Java, Python, C/C++, Scala. Также необходимы навыки работы с базами данных и знание SQL. Будут полезны навыки работы в Linux. Кроме того, существуют специализированные инструменты и библиотеки для использования методов машинного обучения и работы с данными, основные из них:</p>

<ul>
  <li>Библиотеки для Python: NumPy, SciPy, Pandas, IPython, scikit-learn, Nltk, Theano и другие;</li>
  <li>Язык программирования R — специализированный язык для анализа данных, имеет большое количество модулей, реализующих статистические инструменты и методы машинного обучения;</li>
  <li>Weka — инструментарий для анализа данных, написанный на Java;</li>
  <li>Apache Mahout — библиотека, реализованная на Java.</li>
</ul>

<p>Кроме вышеперечисленных, существуют языки Lua и Julia, которые не имеют такого широкого применения в науке о данных, однако в настоящее время для них активно разрабатываются библиотеки для анализа данных.</p>

<p>Важную роль в практической работе с данными играют инструменты Big Data. В их число входят:</p>

<ul>
  <li>Hadoop — реализация модели распределённых вычислений MapReduce и набор различных утилит и библиотек для выполнения распределённых вычислений. В его основе лежит файловая система HDFS;</li>
  <li>Pig — платформа для создания MapReduce приложений с помощью Hadoop; </li>
  <li>Hive, Impala — инфраструктуры хранилища данных, построенного на основе Hadoop;</li>
  <li>Spark — инструментарий для распределённого анализа данных;</li>
  <li>NoSQL базы данных: HBase, MongoDB, Apache Cassandra.</li>
</ul>

<p>На всех этапах анализа данных большую роль играет их визуализация. Полезно взглянуть на некоторые графические представления данных перед началом работы, чтобы лучше понять, какие методы имеет смысл применять. Во время проведения анализа графики могут помочь отобразить промежуточную картину, а после окончания работы с данными с помощью грамотной визуализации можно наглядно представить и объяснить полученные результаты. Рассмотрим основные инструменты визуализации:</p>

<ul>
  <li>Matplotlib — библиотека для языка Python, предназначенная для визуализации в стиле графиков Matlab;</li>
  <li>Язык R содержит большое количество способов визуализации данных. С помощью его инструментов можно легко рисовать различные статистические графики: гистограммы, ящики с усами, диаграммы рассеяния, доверительные интервалы, временные ряды и т.д. Отдельно хочется выделить ggplot2 — мощную библиотеку для создания информативных и красивых графиков;</li>
  <li>D3.js — мощная JavaScript-библиотека для обработки и визуализации данных, с помощью которой можно создавать интерактивные графики.</li>
</ul>

<h2 id="section-2">Прикладные области</h2>

<p>Завершая обзор науки о данных, хочется рассказать об областях её активного применения. Это далеко не полный перечень, в нём представлены наиболее интересные на мой взгляд и получившие в последнее время активное развитие направления. Эти прикладные области во многом связаны с искусственным интеллектом.</p>

<p>Компьютерное зрение (Computer Vision) — это технологии, позволяющие машине решать задачи оптического распознавания объектов. К примерам задач этого класса можно отнести:</p>

<ul>
  <li>Оптическое распознавание символов (Optical Character Recognition, OCR) — распознавание символов, таких как буквы и цифры. Применяется для цифровой обработки и распознавания отсканированных текстов, рукописных текстов, надписей, содержащихся на фотографиях;</li>
  <li>Распознавание образов — идентификация и классификация содержания изображения;</li>
  <li>Отслеживание объекта на видео (tracking);</li>
  <li>Понимание положения — оценка того, какое положение, какую позу занимает объект на изображении;</li>
  <li>Поиск изображения по содержанию — поиск изображений, которые отвечают заданному запросу. Запрос может быть задан различными путями, например, с помощью текста или картинки.</li>
</ul>

<p>Обработка естественного языка (Natural Language Processing, NLP) — технологии, связанные с анализом и синтезом естественных языков. Целью этого направления является разработка систем, понимающих тексты на обычном человеческом языке. Это направление является очень важной частью анализа данных. Примеры задач, которыми занимается NLP:</p>

<ul>
  <li>Тэгирование текста (Part-of-speech tagging) — автоматическое распознавание частей речи слов в тексте. Может применяться для выделения именованных сущностей;</li>
  <li>Построение синтаксического дерева (Parse tree) — с помощью него анализируется смысл предложения;</li>
  <li>Машинный перевод текста с одного языка на другой;</li>
  <li>Информационный поиск;</li>
  <li>Определение темы текста;</li>
  <li>Анализ тональности текста.</li>
</ul>

<p>Распознавание речи (Speech Recognition) и синтез речи — направления исследований, целью которых является создание машин, способных понимать и воспроизводить человеческую речь, что позволит разработать новые более естественные для человека интерфейсы взаимодействия с компьютером.</p>

<p>Современные поисковые системы активно используют разработки в области науки о данных (например, к ним можно отнести известный алгоритм PageRank). Рекомендательные системы, позволяющие определить, что будет интересно пользователю на основе информации о нём и о его действиях в системе, также являются областью приложения для Data Science. Другим активно развивающимся направлением является биоинформатика, которая занимается исследованием генов, структуры белков и биологических систем.</p>

<h2 id="section-3">Заключение</h2>

<p>В этой статье я сделал обзор науки о данных такой, какой я её понимаю. В качестве некоторого summary этого обзора хочу привести прекрасную иллюстрацию дороги, которую необходимо пройти датологу (<a href="http://nirvacana.com/thoughts/becoming-a-data-scientist/">первоисточник</a>):</p>

<p><img src="http://datadeep.ru/images/RoadToDataScientist1.png" title="Data Scientist Road" /></p>

<p>Конечно, невозможно объять необъятное, поэтому специалистов, занимающихся наукой о данных, можно разделить на две категории:</p>

<ol>
  <li>Аналитики — эти люди заточены на анализ данных, чаще всего они приходят их статистики или математики. Они занимаются построением моделей из данных, вытаскиванием из них информации с помощью методов статистики и машинного обучения;</li>
  <li>Разработчики — эти люди прекрасно владеют всем тем, что было описано в разделе “Computer Science и программирование”. Они заточены на создание конечных, работающих с пользователем продуктов. Они умеют добывать, хранить и манипулировать данными.</li>
</ol>

<p>Такая классификация является очень условной, это два крайних класса, чаще всего на практике датологи попадают в среднюю между этими двумя категорию, согласно своим интересам и профессиональным обязанностям. </p>

<p>В дальнейшем в блоге datadeep.ru наша команда будет развивать и дополнять многие темы, затронутые в этой статье.</p>

<h2 id="data-science">Полезные материалы по Data Science</h2>

<p>Существует большое количество литературы, ресурсов в Интернете, online-курсов, посвящённых Data Science. Приведу ссылки на наиболее базовые и полезные на мой взгляд материалы:</p>

<ul>
  <li>Книги по Data Science и Machine Learning:
    <ul>
      <li><a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</a>, Trevor Hastie, Robert Tibshirani, Jerome Friedman;</li>
      <li><a href="http://research.microsoft.com/en-us/um/people/cmbishop/PRML/">Pattern Recognition and Machine Learning</a>, Christopher M. Bishop;</li>
      <li><a href="http://www.cambridge.org/us/academic/subjects/computer-science/knowledge-management-databases-and-data-mining/data-mining-and-analysis-fundamental-concepts-and-algorithms">Data Mining and Analysis: Fundamental Concepts and Algorithms</a>, Mohammed J. Zaki, Wagner Meira Jr.;</li>
      <li><a href="http://www.recognition.mccme.ru/pub/RecognitionLab.html/slbook.pdf">Введение в методы статистического обучения</a>, А. Б. Мерков.</li>
    </ul>
  </li>
  <li>Книги по инструментам Data Science:
    <ul>
      <li><a href="http://shop.oreilly.com/product/0636920023784.do">Python for Data Analysis</a>, Wes McKinney;</li>
      <li><a href="http://shop.oreilly.com/product/0636920018483.do">Machine Learning for Hackers</a>, Drew Conway, John Myles White.</li>
    </ul>
  </li>
  <li>Online-курсы:
    <ul>
      <li><a href="https://www.coursera.org/course/ml">Machine Learning</a> на Coursera, преподаватель Andrew Ng;</li>
      <li><a href="https://www.edx.org/course/caltechx/caltechx-cs1156x-learning-data-2516#.VFqFQfmsWSo">Learning From Data</a> на edX, преподаватель Yaser S. Abu-Mostafa.</li>
    </ul>
  </li>
  <li>Полезные ресурсы, посвящённые Data Science:
    <ul>
      <li><a href="http://www.kdnuggets.com/">KDnuggets.com</a> — ресурс с большим количеством новостей и информации от создателя термина Data Mining Григория Пятецкого-Шапиро; </li>
      <li><a href="http://www.datasciencecentral.com/">datasciencecentral.com</a> — ресурс, содержащий блоги по статистике, машинному обучению и науке о данных в целом;</li>
      <li><a href="http://www.kaggle.com/">kaggle.com</a> — собрание соревнований по Data Science;</li>
      <li><a href="http://machinelearningmastery.com/blog/">machinelearningmastery.com</a> — блог по вопросам, связанным с машинным обучением;</li>
      <li><a href="http://www.machinelearning.ru/wiki/index.php?title=%D0%97%D0%B0%D0%B3%D0%BB%D0%B0%D0%B2%D0%BD%D0%B0%D1%8F_%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B8%D1%86%D0%B0">machinelearning.ru</a> — ресурс, посвящённый машинному обучению и анализу данных.</li>
    </ul>
  </li>
</ul>
]]></content>
  </entry>
  
</feed>
