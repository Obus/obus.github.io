---
layout: post
title: "Оптимизация в машинном обучении"
date: 2014-11-14 12:07:51 +0400
comments: true
categories: [Машинное обучение, Оптимизация]
author: obus
---
 
![enter image description here](http://bayesgroup.ru/wp-content/uploads/2013/04/momo.jpg)
$$
\newcommand{loss}{\ell}
\newcommand{risk}{F}
\newcommand{hyp}{h}
$$
 
Привет, читатель! Обсуждая науку о данных, нельзя не упомянуть машинное обучение. А говоря о машинном обучении, никак невозможно пройти мимо такой темы как *оптимизация*. Что же такое оптимизация и какая она бывает? Как оптимизация связана с машинным обучением? К как быть быстрее, оптимальнее, точнее? 

Если эти вопросы вызывают интерес --- добро пожаловать.
 
<!-- more --> 

## Связь оптимизации и машинного обученния

 
Что такое оптимизация? В двух словах, оптимизация (как область знаний) изучает как *что-то* сделать *лучше*. Вернее, как *что-то* сделать *наилучшим образом*, то есть --- *оптимально*. Оптимальность, обычно, понимается в смысле максимизации или минимизации определенного значения. Например, мы можем искать наиболее выгодную стратегию игры на бирже, максимизируя ожидаемую прибыль, или аэродинамически наиболее эффективную форму кузова автомобиля, минимизируя сопротивление воздуха. Конечно же, этими примерами оптимизация не ограничивается, встречаясь повсеместно. Можно даже придти к выводу, что практически любой процесс --- оптимизационный с той или иной точки зрения, но это уже философия.
 
 
Разобравшись с оптимизацией "на пальцах", определим ее формально. А формально, задача математической оптимизации записывается следующим образом:
 
$$
\risk(\theta) \longrightarrow \min\limits_{\theta\in\mathcal{X}}
$$
 
Так вот, просто и незатейливо. Но постойте, кто эти $$\risk$$, $$\theta$$, $$\mathcal{X}$$ и какое отношение они имеют к машинному обучению?
 
 
Оказывается, большинство задач машинного обучения формулируются именно таким образом: в виде минимизации некоего функционала $$\risk$$ по некоторому параметру $$\theta$$. Например, в случае задачи классификации или регрессии мы стараемся предсказывать одну переменную ($$y$$) на основе другой ($$x$$) с помощью набора функций--"оракулов" $$\{\hyp_\theta\}_{\theta\in\mathcal{X}}$$, выбирая наилучшую из них на основе *обучающей выборки* $$\{x_i, y_i\}_1^N$$ --- в таком случае мы хотим минимизировать ошибку предсказания на имющейся выборке. Ошибку предсказания чаще всего записывают как

$$ \risk(\theta) = \sum_{i=1}^n \loss(\hyp_{\theta}(x_i), y_i),$$ 

где $$\loss(\hyp_{\theta}(x_i), y_i)$$ --- мера отличия предсказания $$\hyp_{\theta}(x_i)$$ от истинного значения $$y_i$$. Чтобы не витать в облаках, рассмотрим конкретный вид $$\risk(\theta)$$ для двух распространенных методов машинного обучения: метода $$K$$-средних и линейной регрессии с квадратичной функцией потерь.
 
#### Метод $$K$$-средних

Этот метод решает задачу задачу кластеризации --- разбиения множества точек $$\{x_i\}_1^N$$ на $$K$$ ($$\leq N$$) непересекающихся множеств--кластеров.  Результат кластеризации методом $K$-средних --- это, во-первых, разбиение множества $\{1,\ldots,N\}$ на $$K$$ кластеров: $$\{\mathcal{C}_k\}_1^K$$ и, во-вторых, центр каждого из кластеров: $$\{c_k\}_1^K$$. Функция $$\risk(\theta)$$ для метода $K$-средних записывается следующим образом
 
$$
\risk\left(\theta = (K, \{\mathcal{C}_k\}_1^K, \{c_k\}_1^K)\right) = \sum_{k=1}^K \sum_{i\in \mathcal{C}_k} (x_i - c_k)^2 \to \min\limits_{\theta},
$$
 
--- $$K$$-средних ищет такое разбиение множества $$\{x_i\}_1^N$$ на кластера, чтобы сумма расстояний от каждой точки до центра кластера, которому она принадлежит, была минимальна.
 
#### Линейная регрессия с квадратичной функцией потерь

Этот метод решает задачу регрессии --- предсказания выходов $$y_i\in\mathrm{R}$$ по входам $$x_i=(x_i^{(1)},\ldots,x_i^{(p)})^T\in\mathrm{R}^p$$ на основе обучающей выборки $$\{ x_i, y_i \}_1^N$$. Метод линейной регрессии "предполагает", что выход $$y$$ может быть представлен в виде линейной комбинации входов $$x_i^{(1)},\ldots,x_i^{(p)}$$: $$y = \sum_{j=1}^p \theta^{(j)} x^{(j)}$$. $$\risk(\theta)$$ записывается следующим образом:
 
$$
\risk(\theta) = \sum_{i=1}^N (x_i^T\theta - y_i)^2 \to \min\limits_{\theta},
$$
 
--- здесь минимизируется среднеквадратичное отклонение "предсказаний" $$x_i^T\theta$$ от истинных значений $$y_i$$.

Таким образом, и метод $$K$$-средних и линейная регрессия минимизируют конкретные функции $$F(\theta)$$ (вся хитрость методов, в том **как** они это делают), решая частные задачи оптимизации. Приложив определенные усилия, функция $$\risk(\theta)$$ может быть выписана для сколь угодно сложной модели, даже для какой-нибудь сверточной нейронной сети (но мы этого делать не будем).

Думаю, что теперь вполне очевидно, что в машинном обучении оптимизация играет очень важную роль.
 
 

## Математическая оптимизация

Решив, что оптимизация в машинном обучении, а значит и в нашем арсенале --- must have, обсудим ее по-подробнее.
 
Математическая оптимизация зародилась в 18--19 века и окончательно оформилась в 20 веке. За этот срок у нее появилось множество видов, подвидов, методов и приложений. Как мы и упомянали выше, общая задача оптимизации ставится следующим образом
 
$$
\risk(\theta) \longrightarrow \min\limits_{\theta\in\mathcal{X}},
$$
 
но от настолько общей постановки мало толку --- совершенно непонятно как ее решать: не имея информации о природе $$\risk$$ и $$\mathcal{X}$$ мы безоружны, можем только в слепую тыкать "пальцем в небо" (вернее, в $$\mathcal{X}$$) в надежде попасть в точку минимума.
Собственно, чем не вариант, есть даже схожий по идее метод, с вполне себе научным название: метод *равномерного поиска* (aka перебора). Суть его, как вы уже догадались, состоит в том, чтобы наложить $$\varepsilon$$-сетку на множество $$\mathcal{X}$$ и измерить функцию $$\risk$$ в каждом узле сетки. Так найдется узел $$\hat\theta$$ с наименьшим значением $$\risk$$, и ... ничего.
Без дополнительных ограничений на $$\risk$$ и/или $$\mathcal{X}$$ наш $$\hat\theta$$ не говорит ничего ни о наимаеньшем значении $$\risk_* = \min\limits_{\theta\in\mathcal{X}} \risk(\theta)$$ не о соответствующем аргументе $$\theta_* = \arg\min\limits_{\theta\in\mathcal{X}} \risk(\theta)$$. Действительно, $$\risk$$ может меняться сколь угодно быстро, принимая между узлами сетки какие угодно значения а то и вовсе быть разрывной, то есть знания о функции в узлах не говорит ничего о ней же вну этих узлов. Так вот, старались-старались, мерели-мерели, а сидим теперь у разбитого корыта.
 
Но унывать всякий может, а надо это дело исправить.

 $$-$$ В чем наша проблема?

 $$-$$ Проблема в излишнней свободе функции $\risk$, точнее в неограниченной скорости ее изменения. 

	Так давайте ее ограничим! Например, вот так:
 
$$
|\risk(\theta_1) - \risk(\theta_2)| \leq L |\theta_1 - \theta_2|,
$$
 
--- мы запретили $$\risk$$ менятся как угодно быстро, ограничив ее изменение линейно изменением ее аргумента (это условие на $$\risk$$, называется *условием Липшица*). Теперь наша оценка $$\hat\theta$$ кое-чего стоит:
 
$$|\risk(\hat\theta) - \risk_*| \leq \varepsilon L \sqrt{p}, $$
 
где $$p$$ --- размерность $$\mathcal{X}$$. Местоположении $$\theta_*$$, однако, до сих пор остается загадкой.
 
Можно продолжить модифицировать метод перебора, добиваясь больших гарантия точности (как по параметру так и позначению функции) и увеличивая вычислительную эффективность (мы вычислили $$\risk$$ порядка $$O\left(\frac{V(\mathcal{X})}{\varepsilon^p}\right)$$ раз, где $$V(\mathcal{X})$$ --- объем $$\mathcal{X}$$, что даже в невинном единичном кубе при $$\varepsilon = 0.01$$ даст миллион). Но это займет немало времени, а метод перебора интересен нам сейчас с той только точки зрения, что демонстрирует две важные идеи.
 
1. [There is no free lucnh](http://www.no-free-lunch.org/). Чтобы эффективно решить задачу оптимизации нам нужно ее ограничить --- сузить круг поисков. Тем быстрее и точнее мы хотим ее решить, тем более жесткие ограничения нам придется накладывать.
2. Лучшее --- враг хорошего. Иногда достаточно найти приближенное к оптимальному решение, сэкономив при этом на ресурсах.
 
Как было сказано, оптимизация как наука обширна и изучает множество различных задач и методов. Все, однако, нам рассматривать не нужно: в машинном обучении актуальны только некоторые из них, в частности очень распространены так называемые *градиентные методы*. Нам градиентные методы интересны как с точки зрения того, что развивают две усвоенные ранее идеи, так и из тех соображений, что они являются основой для многих других методов оптимизации. Именно о градиентных методах и пойдет речь далее.
 

## Градиентные методы

Идея градиентных методов в том, что в каждой точке $$\theta_0$$ мы можем измерить градиент функции $$\nabla \risk(\theta_0)$$, который подскажет нам, как изменяется функция в окрестности $$\theta$$. Попробуем объяснить, откуда растут ноги у этой идеи: зафиксируем $$\theta_0$$, $$\delta$$ и расмотрим разложение функции $$\risk$$ в ряд Тейлора в точке $$\theta_0 + \delta$$:
 
$$
\risk(\theta_0 + \delta) = \risk(\theta_0) +
\nabla \risk(\theta)\delta +
\nabla^2 \risk(\theta_0) \frac{\delta^2}{2} +
\ldots +
\nabla^n \risk(\theta_0) \frac{\delta^n}{n!} +
\ldots
$$
 
$$\delta$$ предполагается достаточно малым, поэтому $$\delta^n$$ убывает очень быстро и обычно рассматривают только первую компоненту:
 
$$
\risk(\theta_0 + \delta) \sim \risk(\theta_0) +
\nabla \risk(\theta)\delta.
$$
 
Таким образом, в окрестности точки $$\theta_0$$ мы приблизили $$\risk$$ линейной функцией. Градиентные методы эксплуатируют это приближение, полагаясь на то, что минимизация $$\risk$$ эквивалентная минимизации ее линейного приближения в небольшой окрестности точки $$\theta_0$$. А что такое "небольшая окрестность"? Ограничим ее шаром с радиусом $$\alpha$$ ($$\mid\delta\mid \leq \alpha$$), тогда на этой окрестности минимум будет достигаться при
 
$$
\delta_* = \arg\min\limits_{|\delta|\leq \alpha} \risk(\theta_0) + \nabla \risk(\theta)\delta = - \alpha\frac{\nabla \risk(\theta)}{|\nabla \risk(\theta)|}.
$$
 
Фактически, мы сделали шажок длиной $$\alpha$$ в направлении *противоположном* направлению градиента $$\nabla \risk(\theta)$$. В этом и заключается основная идея градиентных методов: шаг за шагом, спускаться против направления градиента к минимуму. С этими знаниями можем уже сформулировать простенький алгоритм оптимизации
 
$$
\begin{eqnarray*}
&\textbf{def}& \; \text{simple_gradient_descent}(\risk, \, \theta_0, \, \alpha):
\\
& \quad & k \leftarrow 0
\\
& \quad & \textbf{while} \; not \; tired \; \textbf{do} :
\\
& \quad & \qquad k \leftarrow k + 1
\\
& \quad & \qquad \theta_k \leftarrow \theta_{k-1} - \alpha\frac{\nabla \risk(\theta_{k-1})}{|\nabla \risk(\theta_{k-1})|}
\end{eqnarray*}
$$
 
Действительно, ничего сложного: один за другим делаем шажочки длиной $$\alpha$$ против направления градиента, пока значение функции уменьшается, а как только перестает --- останавливается.
Звучит разумно, но у этого алгоритма есть серьезный недостаток: он учитывает только направление, но не длину градиента. Так мы можем cделать слишком маленький шаг там, где градиент велик тем самым увеличив количество итерации, либо слишком большой шаг там, где градиент мал, пройдя мимо точки оптимума
 
К счастью, мы можем избавится от этих недостатков, немного изменив наш алгоритм
 
$$
\begin{eqnarray*}
&\textbf{def}& \; \text{gradient_descent}(\risk, \, \theta_0, \, \alpha):
\\
& \quad & k \leftarrow 0
\\
& \quad & \textbf{while} \; not \; tired \; \textbf{do} :
\\
& \quad & \qquad k \leftarrow k + 1
\\
& \quad & \qquad \theta_k \leftarrow \theta_{k-1} - \alpha_k\nabla \risk(\theta_{k-1})
\end{eqnarray*}
$$
 
Этот "алгоритм" есть ни что иное, как известный метод *градиентного спуска* (*gradient descent*). Известно, что при некоторых условиях на $$\risk$$ и $$\alpha_k$$ (например, $$\risk$$ выпукла, $$\nabla \risk$$ удовлетворяет условию Липшица, а $$\alpha_k = \alpha$$ ), значение $$\risk$$ в оценках метода градиентного спуска $$\theta_k$$ стремится к оптимальному
 
$$
|\risk(\theta_k) - \risk_*| \xrightarrow{k\to\infty} 0
$$
 
--- это не может не радовать.
 
Теперь у нас есть теоретически обоснованный алгоритм оптимизации, пора применить его в боевых условиях.
 

## Пример. Линейная регрессия с использованием метода градиентного спуска

Выше мы уже упомянали задачу линейной регрессии (с квадратичной функцией ошибки). Напомним ее целевую функцию $$\risk$$:
 
$$
\risk(\theta) = \sum_{i=1}^N (x_i^T\theta - y_i)^2 \to \min\limits_{\theta},
$$
 
В матричном виде она записывается как
 
$$
\risk(\theta) = ||X\theta - y||_2^2 = (X\theta - y)^T (X\theta - y) \to \min\limits_{\theta},
$$
 
где $$X\in\mathbb{R}^{N\times p}$$ --- матрица, чьи строки --- $$x_i$$, а $$y = (y_1,\ldots,y_N)$$.
Существует аналитическое решение этой задачи: $$\hat\theta = (X^T X)^{-1} X^T y$$ (оценка [методом наименьших квадратов](http://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BD%D0%B0%D0%B8%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B8%D1%85_%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82%D0%BE%D0%B2)). Но, во-первых, операция обращения матрицы довольно [дорогая](https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%80%D0%B0%D1%82%D0%BD%D0%B0%D1%8\risk_%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0#.D0.A1.D0.B\risk.D0.BE.D1.81.D0.BE.D0.B1.D1.8B_.D0.BD.D0.B0.D1.85.D0.BE.D0.B6.D0.B4.D0.B5.D0.BD.D0.B8.D1.8\risk_.D0.BE.D0.B1.D1.80.D0.B0.D1.82.D0.BD.D0.BE.D0.B9_.D0.BC.D0.B0.D1.82.D1.80.D0.B8.D1.86.D1.8B), а во-вторых, про существования аналитического решения мы можем и не знать. Допустим, что по определенным причинам мы не можем воспользоваться аналитической формулой.
К счастью, наша функция $$\risk$$ удовлетворяет всем необходимым условиям и для нее выполняется соотношение $$|\risk(\theta_k) - \risk_*| \xrightarrow{k\to\infty} 0$$. Поэтому, мы имеем полное право воспользоваться методом градиентного спуска.
 
В первую очередь нам нужны данные: $$\{x_i, y_i\}_1^N$$, для простоты возьмем модельные ($$N=1000$$):
 
$$
\begin{eqnarray*}
&x^{(1)}_i & \sim \mathcal{N}(0, 1), \quad &i=1,\ldots, 1000
\\
& y_i &= 2 x^{(1)}_i - 0.5 + \varepsilon_i, \qquad &\varepsilon_i \sim \mathcal{N}(0, 1).
\end{eqnarray*}
$$
 
То есть все $$x_i^{(1)}$$ распределены по стандартному нормальному закону, а $$y_i$$ --- линейная функция от $$x_i^{(1)}$$ с аддитивной помехой (так же имеющей стандртное нормальное распределение). Ниже изображены эти данные в плоскости $$(x^{(1)}, y)$$.
![data](http://s18.postimg.org/tzp829i95/data.png)
 
"Лишний" индекс $$(1)$$ к $$x^{(1)}$$ мы добавили не спроста: если обозначить $$x_i^{(2)}=1$$ для всех $$i$$, то можно переписать $$y_i = 2 x_i^{(1)} - \frac{1}{2}x_i^{(2)} + \varepsilon_i$$ и более того
 
$$y = X\theta_* + \varepsilon.$$
 
где $$y=(y_1,\ldots,y_n)^T$$, $$X = \left(x_i^{(j)}\right)_{i,j}$$, $$\varepsilon=(\varepsilon_1,\ldots,\varepsilon_n)^T$$, а $$\theta_*=(2, -\frac{1}{2})$$.
 
Итак, мы определили $$X$$ и $$y$$ (и неизвестный нам по легенде $$\theta_*$$). Для того, чтобы воспользоваться методом градиентного спуска остается найти производную $$\nabla \risk$$, что довольно просто:
 
$$
\nabla \risk(\theta) =\nabla_\theta (X\theta - y)^T (X\theta - y) = X^T (X\theta - y).
$$
 
Теперь все готово. Остается применить метод градиентного спуска к задаче линейной регрессии с сгенерированными нами данными.
Зададим $$\alpha=0.0001$$. Ниже иллюстрируется работа нашего алгоритма: как изменялась линия регрессии, построенная по оценкам $$(\theta_k^{(1)},\theta_k^{(2)})$$, на каждой итерации.
 
![wow](http://gifyu.com/images/LinearRegression_GradientDescent_50iter.gif)
 
#Заключение
Надеюсь, мне удалось ответить на вопросы, заданные в самом начале статьи. Мы поставили общую задачу оптимизации, на паре примеров узнали как она связана с задачей машинного обучения, и логично пришли к методу градиентного спуска, даже применив его на практике. Вполне неплохо, в последующих статьях я постараюсь лучше раскрыть тему применения алгоритмов оптимизации в машинном обучении и прояснить некоторые интересные детали.
 
На последок, порекомендую пару интересных материалов по теме.

* [Введение в оптимизацию. Поляк Б.Т.](http://www.ozon.ru/context/detail/id/1892727/) --- книга от ученого с мировым именем, не только формальным, но и доступным языком рассказывает об основнах оптимизации, помогая уяснить в первую очередь не конкретные задачи и метода, а идеи, стоящие за ними;
* [EE364a: Convex Optimization. Бойд С.](http://web.stanford.edu/class/ee364a/) --- записанные курсы Стэндфордского университета по выпуклой оптимизации (мы этого еще не знаем, но методы выпуклой оптимизации --- если не самые важные, то абсолютно незаменимые в машинном обучении);
* [Методы оптимизации в машинном обучении. Кропотов Д.А.](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4%D1%8B_%D0%BE%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8_%D0%B2_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%BC_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B8_%28%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9%29) --- развернутое содержание курса лекций факультета вычислительной математики и кибернетики МГУ. Без конспектов, к сожалению но с отличной подборкой литературы.

До встречи!

